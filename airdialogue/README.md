# OPE Data for AirDialogue

The data was generated by [Airdialogue Model Transformer](https://github.com/google-research/google-research/tree/master/dialogue_ope/airdialogue_model_transformer).


The `stats.csv` summarize the human evaluation performance (i.e., ground truth) of 4 metrics for each model.

## File structure

There are 4 different settings:
- `opedata`: all human-model evaluation logs
- `opedata_half`: subsampled by 50%
- `opedata_small`: subsampled by 10%
- `opedata_hard`: filter out very similar experence data for each target model. See [below](#opedata_hard).

There are 24 folders within each setting containing pre-processed OPE data for the 24 target models. 

### Data format

The json fileds of `data.json`:
- `dialog`: a sequence of responses  \[e1,a1,a1',e2,a2,a2',...\], where where ei: response from human, ai: response from behavior model, ai': response from target model. 
</br> Each response contains a speaker tag and resposne text. 
</br> **Explanation**: \[e1,a1,e2,a2,...\] is the original experience data. ai' is generated by target model conditioned on previous experience (\[e1,a1,e2,a2,...,ei\]) as illustrated in below.
![data collection](https://user-images.githubusercontent.com/29517186/123739016-efbe5900-d873-11eb-98d2-a3a1e5701fd0.png)

- `reward_ref`: 4 human evaluation score for behavior dialogue (e0,a0,e1,a1,....).
- `reward`: 4 human evaluation score for behavior dialogue (e0,a0,e1,a1,....). Different from `reward_ref`, this reward is obtained by the target model task-specific module (i.e., decision module for booking tickets/ reservation cancellation etc.). It might be more useful than  `reward_ref` for OPE. 
- `kb`: the knowledge base (ticket & reservation information) of the conversation.
- `intent`: the customer intent for the conversation.
- `expected_action`: the gloden action for the customer intent.
- <a id="opedata_hard"></a> For the `opedata_hard` setting, if ai and ai' are similar for all i's, the experience dialogue is filtered out.
- The `data.json` file can be directed used by [ENIGMA](https://github.com/google-research/google-research/tree/master/dialogue_ope/airdialogue_ope).



## Usage of Pre-trained Model

See [Airdialogue Model Transformer](https://github.com/google-research/google-research/tree/master/dialogue_ope/airdialogue_model_transformer) for details. 
The pre-trained model weights can be downloaded from [here](https://www.dropbox.com/s/mf8gf26u0c10j83/air_pretrain_model.tar?dl=0).

## Reference

Jiang, Haoming, et al. "Towards Automatic Evaluation of Dialog Systems: A Model-Free Off-Policy Evaluation Approach."

Wei, Wei, et al. "Airdialogue: An environment for goal-oriented dialogue research." 
